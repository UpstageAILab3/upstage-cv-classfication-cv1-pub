{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augmentation을 적용한 함수 dl모델을 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 증강 함수\n",
    "- A.Resize(height=256, width=256) : 사이즈 변경\n",
    "- A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) : 이미지 픽셀 정규화\n",
    "- A.CoarseDropout(max_holes=16, max_height=16, max_width=16, min_holes=1, min_height=16, min_width=16) : 픽셀 드롭아웃(구멍뚫기)\n",
    "- A.Rotate(limit=(115, 115), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1.0) : 비율 유지하여 회전, 빈공간 흰색\n",
    "- A.VerticalFlip(always_apply=False, p=0.5) : 좌우반전\n",
    "- A.HorizontalFlip(always_apply=False, p=1.0) : 상하반전\n",
    "- A.Blur(always_apply=True, p=1.0, blur_limit=(3, 7)) : 블러\n",
    "- A.GaussNoise(always_apply=False, p=1.0, var_limit=(10.0, 50.0)) : 가우시안, 되는지 의문\n",
    "- A.Downscale(always_apply=False, p=1.0, scale_min=0.35, scale_max=0.35, interpolation=0) : 픽셀다운, 모자이크\n",
    "- 믹스 추가필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, vaild_loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    vaild_preds_list = []\n",
    "    vaild_target_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.float().to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # vaildation set predict\n",
    "    model.eval()\n",
    "    for image, target in tqdm(vaild_loader):\n",
    "        image = image.float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        vaild_preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        vaild_target_list.extend(target.detach().cpu().numpy())\n",
    "    vaild_acc = accuracy_score(vaild_target_list, vaild_preds_list)\n",
    "    vaild_f1 = f1_score(vaild_target_list, vaild_preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"vaild_acc\": vaild_acc,\n",
    "        \"vaild_f1\": vaild_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vaild_preds_list = []\n",
    "# vaild_target_list = []\n",
    "\n",
    "# model.eval()\n",
    "# for image, target in tqdm(vaild_loader):\n",
    "#     image = image.float().to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(image)\n",
    "#     vaild_preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "#     vaild_target_list.extend(target.detach().cpu().numpy())\n",
    "# vaild_acc = accuracy_score(vaild_target_list, preds_list)\n",
    "# vaild_f1 = f1_score(vaild_target_list, preds_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../datasets_fin/'\n",
    "\n",
    "# model config\n",
    "model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 256\n",
    "LR = 1e-3\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일단 단일 augmentation들로 확인\n",
    "- 성능향상시 다양한 데이터증강을 조합하여 추가학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augmentation을 위한 transform 코드\n",
    "# trn_transform = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_coarseDropout = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.CoarseDropout(max_holes=30, max_height=16, max_width=16, min_holes=10, min_height=16, min_width=16, p=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate45 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(45, 45), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate90 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "#     A.Rotate(limit=(90, 90), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate135 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(135, 135), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate180 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(180, 180), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate225 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(225, 225), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1.0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate270 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(270, 270), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1.0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_rotate315 = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Rotate(limit=(315, 315), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1.0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_verticalflip = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.VerticalFlip(always_apply=False, p=1.0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_horizontalflip = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.HorizontalFlip(always_apply=False, p=1.0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_blur = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Blur(always_apply=True, p=1.0, blur_limit=(3, 3)),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_gaussnoise = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.GaussNoise(always_apply=False, p=1.0, var_limit=(500.0, 500.0)),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# trn_transform_downscale = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     A.Downscale(always_apply=False, p=1.0, scale_min=0.5, scale_max=0.5, interpolation=0),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# transform_list = [trn_transform, trn_transform_coarseDropout, trn_transform_rotate45, trn_transform_rotate90, trn_transform_rotate135, trn_transform_rotate180, trn_transform_rotate225,\n",
    "#                   trn_transform_rotate270, trn_transform_rotate315, trn_transform_verticalflip, trn_transform_horizontalflip, trn_transform_blur, trn_transform_gaussnoise,\n",
    "#                   trn_transform_downscale]\n",
    "\n",
    "# # test image 변환을 위한 transform 코드\n",
    "# tst_transform = A.Compose([\n",
    "#     A.Resize(height=img_size, width=img_size),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    A.CoarseDropout(max_holes=30, max_height=16, max_width=16, min_holes=10, min_height=16, min_width=16, p=0.3),\n",
    "    # A.Rotate(limit=(45, 45), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(90, 90), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(135, 135), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(180, 180), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(225, 225), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(270, 270), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    # A.Rotate(limit=(315, 315), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=0.3),\n",
    "    A.Rotate(limit=(0, 360), border_mode=cv2.BORDER_CONSTANT,value=[255, 255, 255], p=1),\n",
    "    A.VerticalFlip(always_apply=False, p=0.3),\n",
    "    A.HorizontalFlip(always_apply=False, p=0.3),\n",
    "    A.Blur(always_apply=True, p=0.3, blur_limit=(3, 3)),\n",
    "    A.GaussNoise(always_apply=False, p=0.3, var_limit=(1000.0, 1000.0)),\n",
    "    A.Downscale(always_apply=False, p=0.3, scale_min=0.5, scale_max=0.5, interpolation=0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_list에서 2개 조합으로 데이터 증강\n",
    "# for i in combinations(transform_list, 2):\n",
    "#     print(i, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 정의를 위한 함수\n",
    "# def make_trn_dataset(transform_list, csv, path):\n",
    "#     trn_dataset = ImageDataset(\n",
    "#         csv,\n",
    "#         path,\n",
    "#         transform=transform_list[0]\n",
    "#     )\n",
    "#     for transform in transform_list[1:]:\n",
    "#         trn_dataset2 = ImageDataset(\n",
    "#             csv,\n",
    "#             path,\n",
    "#             transform=transform\n",
    "#         )\n",
    "#         trn_dataset = ConcatDataset([trn_dataset, trn_dataset2])\n",
    "\n",
    "#     return trn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vaildation set 정의\n",
    "# def make_vaild_dataset(transform_list, csv, path):\n",
    "#     trn_dataset = ImageDataset(\n",
    "#         csv,\n",
    "#         path,\n",
    "#         transform=transform_list[0]\n",
    "#     )\n",
    "#     for transform in transform_list[1:]:\n",
    "#         trn_dataset2 = ImageDataset(\n",
    "#             csv,\n",
    "#             path,\n",
    "#             transform=transform\n",
    "#         )\n",
    "#         trn_dataset = ConcatDataset([trn_dataset, trn_dataset2])\n",
    "\n",
    "#     return trn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17584 2198 157\n"
     ]
    }
   ],
   "source": [
    "# trn_dataset = make_trn_dataset(transform_list, \"../datasets_fin/divided_train.csv\", \"../datasets_fin/train/\")\n",
    "# vaild_dataset = make_vaild_dataset(transform_list, \"../datasets_fin/vaild.csv\", \"../datasets_fin/train/\",)\n",
    "# tst_dataset = ImageDataset(\n",
    "#     \"../datasets_fin/test.csv\",\n",
    "#     \"../datasets_fin/train/\",\n",
    "#     transform=tst_transform\n",
    "# )\n",
    "# print(len(trn_dataset), len(vaild_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256 157 157\n"
     ]
    }
   ],
   "source": [
    "# Dataset 정의를 위한 함수\n",
    "trn_dataset = ImageDataset(\n",
    "    \"../datasets_fin/divided_train.csv\",\n",
    "    \"../datasets_fin/train/\",\n",
    "    transform=trn_transform\n",
    ")\n",
    "vaild_dataset = ImageDataset(\n",
    "    \"../datasets_fin/vaild.csv\",\n",
    "    \"../datasets_fin/train/\",\n",
    "    transform=trn_transform\n",
    ")\n",
    "tst_dataset = ImageDataset(\n",
    "    \"../datasets_fin/test.csv\",\n",
    "    \"../datasets_fin/train/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(vaild_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "vaild_loader = DataLoader(\n",
    "    vaild_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.9084: 100%|██████████| 40/40 [00:11<00:00,  3.56it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 2.8271\n",
      "train_acc: 0.0613\n",
      "train_f1: 0.0270\n",
      "vaild_acc: 0.0828\n",
      "vaild_f1: 0.0159\n",
      "epoch: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6589: 100%|██████████| 40/40 [00:10<00:00,  3.91it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 2.5468\n",
      "train_acc: 0.1465\n",
      "train_f1: 0.1197\n",
      "vaild_acc: 0.1274\n",
      "vaild_f1: 0.0902\n",
      "epoch: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7419: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 2.0989\n",
      "train_acc: 0.3057\n",
      "train_f1: 0.2677\n",
      "vaild_acc: 0.1210\n",
      "vaild_f1: 0.0685\n",
      "epoch: 2.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7742: 100%|██████████| 40/40 [00:10<00:00,  3.89it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.7798\n",
      "train_acc: 0.3965\n",
      "train_f1: 0.3628\n",
      "vaild_acc: 0.2038\n",
      "vaild_f1: 0.1387\n",
      "epoch: 3.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2705: 100%|██████████| 40/40 [00:10<00:00,  3.93it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.6354\n",
      "train_acc: 0.4554\n",
      "train_f1: 0.4325\n",
      "vaild_acc: 0.1465\n",
      "vaild_f1: 0.0844\n",
      "epoch: 4.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6746: 100%|██████████| 40/40 [00:10<00:00,  3.84it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.5348\n",
      "train_acc: 0.4857\n",
      "train_f1: 0.4622\n",
      "vaild_acc: 0.4076\n",
      "vaild_f1: 0.3538\n",
      "epoch: 5.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2193: 100%|██████████| 40/40 [00:10<00:00,  3.91it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.4066\n",
      "train_acc: 0.5239\n",
      "train_f1: 0.5055\n",
      "vaild_acc: 0.0828\n",
      "vaild_f1: 0.0425\n",
      "epoch: 6.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7388: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train_loss: 1.3737\n",
      "train_acc: 0.5303\n",
      "train_f1: 0.5192\n",
      "vaild_acc: 0.1911\n",
      "vaild_f1: 0.1405\n",
      "epoch: 7.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9409: 100%|██████████| 40/40 [00:10<00:00,  3.81it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.4044\n",
      "train_acc: 0.5223\n",
      "train_f1: 0.5417\n",
      "vaild_acc: 0.4650\n",
      "vaild_f1: 0.4699\n",
      "epoch: 8.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7856: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.3513\n",
      "train_acc: 0.5533\n",
      "train_f1: 0.5598\n",
      "vaild_acc: 0.3631\n",
      "vaild_f1: 0.3040\n",
      "epoch: 9.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8594: 100%|██████████| 40/40 [00:10<00:00,  3.82it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train_loss: 1.3525\n",
      "train_acc: 0.5326\n",
      "train_f1: 0.5288\n",
      "vaild_acc: 0.4841\n",
      "vaild_f1: 0.4677\n",
      "epoch: 10.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8614: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.3307\n",
      "train_acc: 0.5653\n",
      "train_f1: 0.5808\n",
      "vaild_acc: 0.4777\n",
      "vaild_f1: 0.4921\n",
      "epoch: 11.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9713: 100%|██████████| 40/40 [00:10<00:00,  3.91it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.2231\n",
      "train_acc: 0.5828\n",
      "train_f1: 0.6000\n",
      "vaild_acc: 0.3949\n",
      "vaild_f1: 0.3553\n",
      "epoch: 12.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4570: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train_loss: 1.2402\n",
      "train_acc: 0.5709\n",
      "train_f1: 0.5904\n",
      "vaild_acc: 0.3057\n",
      "vaild_f1: 0.3394\n",
      "epoch: 13.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6642: 100%|██████████| 40/40 [00:10<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.2277\n",
      "train_acc: 0.5836\n",
      "train_f1: 0.5873\n",
      "vaild_acc: 0.5350\n",
      "vaild_f1: 0.5014\n",
      "epoch: 14.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3206: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.3476\n",
      "train_acc: 0.5605\n",
      "train_f1: 0.5755\n",
      "vaild_acc: 0.4076\n",
      "vaild_f1: 0.3792\n",
      "epoch: 15.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6219: 100%|██████████| 40/40 [00:10<00:00,  3.86it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train_loss: 1.2529\n",
      "train_acc: 0.5844\n",
      "train_f1: 0.5956\n",
      "vaild_acc: 0.2229\n",
      "vaild_f1: 0.1920\n",
      "epoch: 16.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9922: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "train_loss: 1.2086\n",
      "train_acc: 0.5932\n",
      "train_f1: 0.6205\n",
      "vaild_acc: 0.3758\n",
      "vaild_f1: 0.3596\n",
      "epoch: 17.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4895: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "train_loss: 1.1722\n",
      "train_acc: 0.5971\n",
      "train_f1: 0.6022\n",
      "vaild_acc: 0.3376\n",
      "vaild_f1: 0.3052\n",
      "epoch: 18.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6638: 100%|██████████| 40/40 [00:10<00:00,  3.92it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "train_loss: 1.1517\n",
      "train_acc: 0.6051\n",
      "train_f1: 0.6169\n",
      "vaild_acc: 0.3439\n",
      "vaild_f1: 0.3450\n",
      "epoch: 19.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2315: 100%|██████████| 40/40 [00:10<00:00,  3.92it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "train_loss: 1.1177\n",
      "train_acc: 0.6266\n",
      "train_f1: 0.6520\n",
      "vaild_acc: 0.1656\n",
      "vaild_f1: 0.1379\n",
      "epoch: 20.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0576: 100%|██████████| 40/40 [00:10<00:00,  3.86it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "train_loss: 1.1718\n",
      "train_acc: 0.6035\n",
      "train_f1: 0.5999\n",
      "vaild_acc: 0.4777\n",
      "vaild_f1: 0.4633\n",
      "epoch: 21.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0471: 100%|██████████| 40/40 [00:10<00:00,  3.86it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "train_loss: 1.1819\n",
      "train_acc: 0.5876\n",
      "train_f1: 0.5876\n",
      "vaild_acc: 0.4204\n",
      "vaild_f1: 0.4203\n",
      "epoch: 22.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7917: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "train_loss: 1.1181\n",
      "train_acc: 0.6210\n",
      "train_f1: 0.6514\n",
      "vaild_acc: 0.3822\n",
      "vaild_f1: 0.3846\n",
      "epoch: 23.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7343: 100%|██████████| 40/40 [00:10<00:00,  3.89it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.1478\n",
      "train_acc: 0.6019\n",
      "train_f1: 0.6110\n",
      "vaild_acc: 0.5287\n",
      "vaild_f1: 0.5282\n",
      "epoch: 24.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2149: 100%|██████████| 40/40 [00:10<00:00,  3.84it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.1218\n",
      "train_acc: 0.6226\n",
      "train_f1: 0.6416\n",
      "vaild_acc: 0.5223\n",
      "vaild_f1: 0.5312\n",
      "epoch: 25.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4372: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train_loss: 1.1368\n",
      "train_acc: 0.6051\n",
      "train_f1: 0.6155\n",
      "vaild_acc: 0.6051\n",
      "vaild_f1: 0.6175\n",
      "epoch: 26.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6187: 100%|██████████| 40/40 [00:10<00:00,  3.90it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train_loss: 1.1252\n",
      "train_acc: 0.6218\n",
      "train_f1: 0.6361\n",
      "vaild_acc: 0.3949\n",
      "vaild_f1: 0.3777\n",
      "epoch: 27.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8432: 100%|██████████| 40/40 [00:10<00:00,  3.89it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train_loss: 1.1035\n",
      "train_acc: 0.6194\n",
      "train_f1: 0.6181\n",
      "vaild_acc: 0.1911\n",
      "vaild_f1: 0.1735\n",
      "epoch: 28.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8396: 100%|██████████| 40/40 [00:10<00:00,  3.91it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "train_loss: 1.0975\n",
      "train_acc: 0.6242\n",
      "train_f1: 0.6446\n",
      "vaild_acc: 0.4841\n",
      "vaild_f1: 0.4509\n",
      "epoch: 29.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3708: 100%|██████████| 40/40 [00:10<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "train_loss: 1.1208\n",
      "train_acc: 0.6075\n",
      "train_f1: 0.6249\n",
      "vaild_acc: 0.5159\n",
      "vaild_f1: 0.5119\n",
      "epoch: 30.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6044: 100%|██████████| 40/40 [00:10<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "train_loss: 1.1675\n",
      "train_acc: 0.6051\n",
      "train_f1: 0.6174\n",
      "vaild_acc: 0.4904\n",
      "vaild_f1: 0.4478\n",
      "epoch: 31.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1515: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "train_loss: 1.1425\n",
      "train_acc: 0.6178\n",
      "train_f1: 0.6401\n",
      "vaild_acc: 0.0828\n",
      "vaild_f1: 0.0516\n",
      "epoch: 32.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6018: 100%|██████████| 40/40 [00:10<00:00,  3.84it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "train_loss: 1.0635\n",
      "train_acc: 0.6377\n",
      "train_f1: 0.6475\n",
      "vaild_acc: 0.5796\n",
      "vaild_f1: 0.5664\n",
      "epoch: 33.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6847: 100%|██████████| 40/40 [00:10<00:00,  3.93it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "train_loss: 1.0234\n",
      "train_acc: 0.6481\n",
      "train_f1: 0.6642\n",
      "vaild_acc: 0.4331\n",
      "vaild_f1: 0.4101\n",
      "epoch: 34.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3225: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "train_loss: 1.0697\n",
      "train_acc: 0.6393\n",
      "train_f1: 0.6616\n",
      "vaild_acc: 0.3376\n",
      "vaild_f1: 0.3003\n",
      "epoch: 35.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1062: 100%|██████████| 40/40 [00:10<00:00,  3.85it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "train_loss: 1.1244\n",
      "train_acc: 0.6115\n",
      "train_f1: 0.6273\n",
      "vaild_acc: 0.4522\n",
      "vaild_f1: 0.4516\n",
      "epoch: 36.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7593: 100%|██████████| 40/40 [00:10<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "train_loss: 1.0691\n",
      "train_acc: 0.6425\n",
      "train_f1: 0.6566\n",
      "vaild_acc: 0.3567\n",
      "vaild_f1: 0.3150\n",
      "epoch: 37.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0871: 100%|██████████| 40/40 [00:10<00:00,  3.85it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "train_loss: 1.1384\n",
      "train_acc: 0.6202\n",
      "train_f1: 0.6451\n",
      "vaild_acc: 0.3949\n",
      "vaild_f1: 0.3626\n",
      "epoch: 38.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9169: 100%|██████████| 40/40 [00:10<00:00,  3.94it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "train_loss: 1.0357\n",
      "train_acc: 0.6656\n",
      "train_f1: 0.6970\n",
      "vaild_acc: 0.4268\n",
      "vaild_f1: 0.4133\n",
      "epoch: 39.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop = 0\n",
    "best_model = model\n",
    "best_epoch = 0\n",
    "best_vaild_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "   if early_stop > 100: # earlystop없이 모든 애폭을 사용하여 학습, 단 best model을 따로 저장\n",
    "      torch.save(best_model, '../model/best_augmentation3_'+str(img_size)+'_'+str(best_epoch)+'.pt')\n",
    "      break\n",
    "   ret = train_one_epoch(trn_loader, vaild_loader, model, optimizer, loss_fn, device=device)\n",
    "   ret['epoch'] = epoch\n",
    "   if best_vaild_f1 < ret['vaild_f1']:\n",
    "      best_vaild_f1 = ret['vaild_f1']\n",
    "      best_model = model\n",
    "      best_epoch = epoch+1\n",
    "      early_stop = 0\n",
    "   else:\n",
    "      early_stop += 1\n",
    "\n",
    "   print(early_stop)\n",
    "\n",
    "   log = \"\"\n",
    "   for k, v in ret.items():\n",
    "      log += f\"{k}: {v:.4f}\\n\"\n",
    "   print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, '../model/best_augmentation4_'+str(img_size)+'_'+str(best_epoch)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(20):\n",
    "#     ret = train_one_epoch(trn_loader, vaild_loader, model, optimizer, loss_fn, device=device)\n",
    "#     ret['epoch'] = epoch\n",
    "\n",
    "#     log = \"\"\n",
    "#     for k, v in ret.items():\n",
    "#       log += f\"{k}: {v:.4f}\\n\"\n",
    "#     print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../model/best_augmentation4_'+str(img_size)+'_'+str(best_epoch)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7006369426751592, 0.6772020129650798)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터 확인\n",
    "tst_preds_list = []\n",
    "tst_target_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, target in tqdm(tst_loader):\n",
    "    image = image.float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    tst_preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "    tst_target_list.extend(target.detach().cpu().numpy())\n",
    "tst_acc = accuracy_score(tst_target_list, tst_preds_list)\n",
    "tst_f1 = f1_score(tst_target_list, tst_preds_list, average='macro')\n",
    "\n",
    "tst_acc, tst_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 test데이터\n",
    "test_dataset = ImageDataset(\n",
    "    \"../datasets_fin/sample_submission.csv\",\n",
    "    \"../datasets_fin/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:14<00:00,  6.99it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"../datasets_fin/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"../output/augmentation4_pred_256_\"+str(best_epoch)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg       3\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
